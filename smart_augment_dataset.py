#!/usr/bin/env python3
"""
Smart Dataset Augmentation for Medical Intent Classification
TÄƒng cÆ°á»ng dataset thÃ´ng minh - trÃ¡nh trÃ¹ng láº·p vÃ  há»c váº¹t
"""

import pandas as pd
import numpy as np
import json
import re
import random
from typing import List, Dict, Set
from collections import defaultdict, Counter
import itertools

class SmartDatasetAugmenter:
    def __init__(self):
        # Synonyms vÃ  variations cho tá»«ng loáº¡i intent
        self.symptom_variations = {
            'má»‡t má»i': ['má»‡t má»i', 'kiá»‡t sá»©c', 'má»‡t láº£', 'uá»ƒ oáº£i', 'má»i má»‡t', 'thiáº¿u sá»©c lá»±c', 'khÃ´ng cÃ²n sá»©c'],
            'Ä‘au Ä‘áº§u': ['Ä‘au Ä‘áº§u', 'nhá»©c Ä‘áº§u', 'Ä‘au ná»­a Ä‘áº§u', 'choÃ¡ng vÃ¡ng', 'hoa máº¯t', 'chÃ³ng máº·t'],
            'Ä‘au bá»¥ng': ['Ä‘au bá»¥ng', 'Ä‘au dáº¡ dÃ y', 'Ä‘au tá»¥y', 'buá»“n nÃ´n', 'khÃ³ tiÃªu'],
            'sá»‘t': ['sá»‘t', 'sá»‘t cao', 'sá»‘t nháº¹', 'á»›n láº¡nh', 'run ráº©y', 'nÃ³ng ngÆ°á»i'],
            'ho': ['ho', 'ho khan', 'ho cÃ³ Ä‘á»m', 'ho mÃ£n tÃ­nh', 'ho khÃ´ng ngá»«ng'],
            'Ä‘au há»ng': ['Ä‘au há»ng', 'viÃªm há»ng', 'khÃ´ há»ng', 'rÃ¡t há»ng', 'nuá»‘t khÃ³'],
            'chÃ¡n Äƒn': ['chÃ¡n Äƒn', 'máº¥t cáº£m giÃ¡c ngon miá»‡ng', 'khÃ´ng muá»‘n Äƒn', 'biáº¿ng Äƒn'],
            'ngá»©a': ['ngá»©a', 'ngá»©a máº©n Ä‘á»', 'ngá»©a khÃ³ chá»‹u', 'da ngá»©a'],
            'tiÃªu cháº£y': ['tiÃªu cháº£y', 'Ä‘i ngoÃ i lá»ng', 'bá»¥ng xoáº¯n', 'Ä‘au bá»¥ng Ä‘i ngoÃ i'],
            'tÃ¡o bÃ³n': ['tÃ¡o bÃ³n', 'khÃ³ Ä‘i ngoÃ i', 'Ä‘áº¡i tiá»‡n khÃ³', 'bÃ­ bá»¥ng'],
            'khÃ³ thá»Ÿ': ['khÃ³ thá»Ÿ', 'thá»Ÿ gáº¥p', 'há»¥t hÆ¡i', 'thiáº¿u hÆ¡i', 'ngáº¡t thá»Ÿ']
        }
        
        self.drug_variations = {
            'paracetamol': ['paracetamol', 'acetaminophen', 'Panadol', 'Efferalgan', 'Tylenol'],
            'amoxicillin': ['amoxicillin', 'Amoxil', 'Augmentin', 'Clamoxyl'],
            'aspirin': ['aspirin', 'acetylsalicylic acid', 'Cardiprin', 'Bayer'],
            'ibuprofen': ['ibuprofen', 'Brufen', 'Advil', 'Nurofen'],
            'metformin': ['metformin', 'Glucophage', 'Diabetmin'],
            'omeprazole': ['omeprazole', 'Losec', 'Prilosec'],
            'cetirizine': ['cetirizine', 'Zyrtec', 'Reactine']
        }
        
        # CÃ¡c cÃ¡ch diá»…n Ä‘áº¡t khÃ¡c nhau
        self.question_patterns = {
            'symptom_inquiry': [
                "TÃ´i bá»‹ {symptom}",
                "TÃ´i cÃ³ triá»‡u chá»©ng {symptom}",
                "CÃ³ dáº¥u hiá»‡u {symptom}",
                "Xuáº¥t hiá»‡n triá»‡u chá»©ng {symptom}",
                "Máº¥y ngÃ y nay {symptom}",
                "Tuáº§n nÃ y {symptom}",
                "HÃ´m nay {symptom}",
                "Tá»« sÃ¡ng {symptom}",
                "Gáº§n Ä‘Ã¢y {symptom}",
                "LÃ m sao Ä‘á»ƒ chá»¯a {symptom}?",
                "CÃ¡ch Ä‘iá»u trá»‹ {symptom}",
                "Thuá»‘c gÃ¬ chá»¯a {symptom}?",
                "Triá»‡u chá»©ng {symptom} lÃ  gÃ¬?",
                "{family_member} bá»‹ {symptom}",
                "Con tÃ´i cÃ³ {symptom}",
                "Vá»£/chá»“ng tÃ´i {symptom}"
            ],
            'drug_question': [
                "Thuá»‘c {drug} cÃ³ tÃ¡c dá»¥ng gÃ¬?",
                "{drug} lÃ  thuá»‘c gÃ¬?",
                "CÃ´ng dá»¥ng cá»§a {drug}",
                "TÃ¡c dá»¥ng thuá»‘c {drug}",
                "{drug} dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬?",
                "Thuá»‘c {drug} chá»¯a bá»‡nh gÃ¬?",
                "CÃ¡ch sá»­ dá»¥ng thuá»‘c {drug}",
                "ThÃ nh pháº§n cá»§a {drug}",
                "ThÃ´ng tin vá» thuá»‘c {drug}",
                "{drug} cÃ³ hiá»‡u quáº£ khÃ´ng?"
            ],
            'dosage_question': [
                "Liá»u lÆ°á»£ng thuá»‘c {drug}",
                "CÃ¡ch uá»‘ng {drug}",
                "Thuá»‘c {drug} uá»‘ng lÃºc nÃ o?",
                "Thuá»‘c {drug} uá»‘ng trÆ°á»›c hay sau Äƒn?",
                "Má»™t ngÃ y uá»‘ng {drug} máº¥y láº§n?",
                "Liá»u dÃ¹ng {drug} cho ngÆ°á»i lá»›n",
                "CÃ¡ch dÃ¹ng {drug} Ä‘Ãºng cÃ¡ch",
                "Thá»i gian uá»‘ng {drug}",
                "Khoáº£ng cÃ¡ch giá»¯a cÃ¡c láº§n uá»‘ng {drug}",
                "Lá»‹ch uá»‘ng thuá»‘c {drug}"
            ],
            'side_effects': [
                "Thuá»‘c {drug} cÃ³ tÃ¡c dá»¥ng phá»¥ gÃ¬?",
                "TÃ¡c dá»¥ng phá»¥ cá»§a {drug}",
                "Sau khi uá»‘ng {drug} bá»‹ {symptom}",
                "Uá»‘ng {drug} cÃ³ háº¡i gÃ¬ khÃ´ng?",
                "Pháº£n á»©ng phá»¥ cá»§a {drug}",
                "TÃ¡c háº¡i cá»§a thuá»‘c {drug}",
                "{drug} cÃ³ an toÃ n khÃ´ng?",
                "LÆ°u Ã½ khi dÃ¹ng {drug}",
                "Chá»‘ng chá»‰ Ä‘á»‹nh cá»§a {drug}",
                "Thuá»‘c {drug} cÃ³ Ä‘á»™c khÃ´ng?"
            ]
        }
        
        self.family_members = [
            "con tÃ´i", "vá»£ tÃ´i", "chá»“ng tÃ´i", "bá»‘ tÃ´i", "máº¹ tÃ´i", 
            "bÃ  ngoáº¡i", "Ã´ng ngoáº¡i", "em bÃ©", "anh áº¥y", "chá»‹ áº¥y",
            "cáº­u bÃ©", "cÃ´ gÃ¡i", "ngÆ°á»i báº¡n", "Ä‘á»“ng nghiá»‡p"
        ]
        
        self.time_expressions = [
            "hÃ´m nay", "hÃ´m qua", "máº¥y ngÃ y nay", "tuáº§n nÃ y", "thÃ¡ng nÃ y",
            "tá»« sÃ¡ng", "tá»« tá»‘i qua", "tá»« hÃ´m qua", "gáº§n Ä‘Ã¢y", "thá»i gian gáº§n Ä‘Ã¢y",
            "má»™t thá»i gian", "lÃ¢u nay", "má»›i Ä‘Ã¢y"
        ]
        
    def load_existing_data(self, file_path: str) -> pd.DataFrame:
        """Load existing clean dataset"""
        df = pd.read_csv(file_path)
        # Remove quotes if any
        df['text'] = df['text'].str.strip('"')
        return df
    
    def extract_patterns(self, df: pd.DataFrame) -> Dict:
        """PhÃ¢n tÃ­ch patterns tá»« dá»¯ liá»‡u hiá»‡n cÃ³"""
        patterns = {
            'symptoms': set(),
            'drugs': set(),
            'templates': defaultdict(list)
        }
        
        for _, row in df.iterrows():
            text = row['text'].lower()
            intent = row['intent']
            
            # Extract symptoms (tá»« symptom_inquiry)
            if intent == 'symptom_inquiry':
                # TÃ¬m patterns phá»• biáº¿n
                if 'bá»‹' in text:
                    symptom = re.search(r'bá»‹\s+(.+?)(?:\s|$)', text)
                    if symptom:
                        patterns['symptoms'].add(symptom.group(1).strip())
                        
                if 'triá»‡u chá»©ng' in text:
                    symptom = re.search(r'triá»‡u chá»©ng\s+(.+?)(?:\s|$)', text)
                    if symptom:
                        patterns['symptoms'].add(symptom.group(1).strip())
            
            # Extract drug names
            if intent in ['drug_question', 'dosage_question', 'side_effects']:
                # TÃ¬m tÃªn thuá»‘c
                for drug_name in self.drug_variations.keys():
                    if drug_name in text:
                        patterns['drugs'].add(drug_name)
                        
            # LÆ°u template chung
            patterns['templates'][intent].append(text)
            
        return patterns
    
    def generate_variations(self, original_text: str, intent: str, count: int = 5) -> List[str]:
        """Táº¡o variations cá»§a má»™t cÃ¢u gá»‘c"""
        variations = []
        original_lower = original_text.lower()
        
        if intent == 'symptom_inquiry':
            # Thay tháº¿ symptoms báº±ng synonyms
            for symptom, synonyms in self.symptom_variations.items():
                if symptom in original_lower:
                    for synonym in synonyms[:3]:  # Chá»‰ láº¥y 3 synonym
                        new_text = original_text.replace(symptom, synonym)
                        if new_text != original_text:
                            variations.append(new_text)
                            
            # Thay tháº¿ time expressions
            for time_expr in self.time_expressions:
                if any(t in original_lower for t in ['hÃ´m nay', 'máº¥y ngÃ y', 'tuáº§n nÃ y']):
                    new_text = re.sub(r'(hÃ´m nay|máº¥y ngÃ y nay|tuáº§n nÃ y|thÃ¡ng nÃ y)', 
                                    time_expr, original_text, flags=re.IGNORECASE)
                    if new_text != original_text:
                        variations.append(new_text)
                        
        elif intent in ['drug_question', 'dosage_question', 'side_effects']:
            # Thay tháº¿ drug names báº±ng synonyms
            for drug, synonyms in self.drug_variations.items():
                if drug in original_lower:
                    for synonym in synonyms[:2]:  # Chá»‰ láº¥y 2 synonym
                        new_text = original_text.replace(drug, synonym)
                        if new_text != original_text:
                            variations.append(new_text)
        
        # ThÃªm variations vá» structure
        structure_variations = self._create_structure_variations(original_text, intent)
        variations.extend(structure_variations)
        
        # Loáº¡i bá» trÃ¹ng láº·p vÃ  giá»›i háº¡n sá»‘ lÆ°á»£ng
        unique_variations = list(set(variations))
        return unique_variations[:count]
    
    def _create_structure_variations(self, text: str, intent: str) -> List[str]:
        """Táº¡o variations vá» cáº¥u trÃºc cÃ¢u"""
        variations = []
        text_lower = text.lower()
        
        if intent == 'symptom_inquiry':
            # "TÃ´i bá»‹ X" -> "CÃ³ triá»‡u chá»©ng X", "Xuáº¥t hiá»‡n X"
            if text_lower.startswith('tÃ´i bá»‹'):
                symptom = text[7:]  # Bá» "TÃ´i bá»‹ "
                variations.extend([
                    f"CÃ³ triá»‡u chá»©ng {symptom.lower()}",
                    f"Xuáº¥t hiá»‡n triá»‡u chá»©ng {symptom.lower()}",
                    f"CÃ³ dáº¥u hiá»‡u {symptom.lower()}"
                ])
            
            # "CÃ³ triá»‡u chá»©ng X" -> "TÃ´i bá»‹ X"
            elif 'cÃ³ triá»‡u chá»©ng' in text_lower:
                symptom = re.search(r'cÃ³ triá»‡u chá»©ng\s+(.+)', text_lower)
                if symptom:
                    variations.append(f"TÃ´i bá»‹ {symptom.group(1)}")
                    
        elif intent == 'drug_question':
            # "Thuá»‘c X cÃ³ tÃ¡c dá»¥ng gÃ¬?" -> "X lÃ  thuá»‘c gÃ¬?"
            if 'cÃ³ tÃ¡c dá»¥ng gÃ¬' in text_lower:
                drug = re.search(r'thuá»‘c\s+(\w+)', text_lower)
                if drug:
                    variations.extend([
                        f"{drug.group(1)} lÃ  thuá»‘c gÃ¬?",
                        f"CÃ´ng dá»¥ng cá»§a {drug.group(1)}",
                        f"TÃ¡c dá»¥ng thuá»‘c {drug.group(1)}"
                    ])
        
        return variations
    
    def generate_smart_combinations(self, df: pd.DataFrame, target_size: int = 5000) -> List[Dict]:
        """Táº¡o combinations thÃ´ng minh"""
        augmented_data = []
        existing_texts = set(df['text'].str.lower())
        
        # Äáº§u tiÃªn, copy táº¥t cáº£ data gá»‘c
        for _, row in df.iterrows():
            augmented_data.append({
                'text': row['text'],
                'intent': row['intent'],
                'category': row['category'],
                'confidence': row['confidence']
            })
        
        # PhÃ¢n tÃ­ch intent distribution
        intent_counts = df['intent'].value_counts()
        print(f"ğŸ“Š Intent distribution hiá»‡n táº¡i:")
        for intent, count in intent_counts.items():
            print(f"  {intent}: {count}")
        
        # Calculate target distribution (balanced)
        target_per_intent = target_size // len(intent_counts)
        
        for intent in intent_counts.index:
            current_count = intent_counts[intent]
            needed = max(0, target_per_intent - current_count)
            
            print(f"ğŸ¯ {intent}: cÃ³ {current_count}, cáº§n thÃªm {needed}")
            
            if needed > 0:
                intent_data = df[df['intent'] == intent]
                generated = self._generate_for_intent(intent_data, needed, existing_texts)
                augmented_data.extend(generated)
                
                # Update existing_texts Ä‘á»ƒ trÃ¡nh trÃ¹ng láº·p
                for item in generated:
                    existing_texts.add(item['text'].lower())
        
        return augmented_data
    
    def _generate_for_intent(self, intent_data: pd.DataFrame, needed: int, existing_texts: Set[str]) -> List[Dict]:
        """Generate data cho má»™t intent cá»¥ thá»ƒ"""
        generated = []
        intent = intent_data.iloc[0]['intent']
        category = intent_data.iloc[0]['category']
        
        attempts = 0
        max_attempts = needed * 10  # Giá»›i háº¡n sá»‘ láº§n thá»­
        
        while len(generated) < needed and attempts < max_attempts:
            attempts += 1
            
            # Chá»n random má»™t sample gá»‘c
            sample = intent_data.sample(1).iloc[0]
            original_text = sample['text']
            
            # Táº¡o variations
            variations = self.generate_variations(original_text, intent, count=10)
            
            for variation in variations:
                if variation.lower() not in existing_texts:
                    generated.append({
                        'text': variation,
                        'intent': intent,
                        'category': category,
                        'confidence': 0.8  # Lower confidence for generated data
                    })
                    existing_texts.add(variation.lower())
                    
                    if len(generated) >= needed:
                        break
            
            # Náº¿u khÃ´ng Ä‘á»§ variations, táº¡o tá»« template
            if len(generated) < needed:
                template_variations = self._generate_from_templates(intent, existing_texts)
                for variation in template_variations:
                    if len(generated) >= needed:
                        break
                    generated.append({
                        'text': variation,
                        'intent': intent,
                        'category': category,
                        'confidence': 0.7
                    })
                    existing_texts.add(variation.lower())
        
        print(f"  âœ… ÄÃ£ táº¡o {len(generated)} máº«u cho {intent}")
        return generated
    
    def _generate_from_templates(self, intent: str, existing_texts: Set[str], count: int = 50) -> List[str]:
        """Táº¡o tá»« templates cÃ³ sáºµn - An toÃ n vá»›i missing variables"""
        generated = []
        
        if intent not in self.question_patterns:
            return generated
            
        templates = self.question_patterns[intent]
        
        # Chuáº©n bá»‹ cÃ¡c variables Ä‘á»ƒ fill template
        variables = {
            'symptom': list(self.symptom_variations.keys()),
            'drug': list(self.drug_variations.keys()),
            'family_member': self.family_members,
            'age': ['tráº» em', 'ngÆ°á»i lá»›n', 'ngÆ°á»i giÃ ', 'bÃ©', 'Ã´ng bÃ '],
            'severity': ['nháº¹', 'vá»«a pháº£i', 'náº·ng', 'nghiÃªm trá»ng'],
            'duration': ['hÃ´m qua', 'máº¥y ngÃ y nay', 'tuáº§n nÃ y', 'tá»« lÃ¢u']
        }
        
        for template in templates:
            # TÃ¬m táº¥t cáº£ variables trong template
            import re
            template_vars = re.findall(r'\{(\w+)\}', template)
            
            if not template_vars:
                # Template khÃ´ng cÃ³ biáº¿n
                if template.lower() not in existing_texts:
                    generated.append(template)
                continue
            
            # Táº¡o combinations cho cÃ¡c variables
            if len(template_vars) == 1:
                # Template cÃ³ 1 biáº¿n
                var_name = template_vars[0]
                if var_name in variables:
                    for value in variables[var_name][:10]:  # Limit 10 per variable
                        try:
                            text = template.format(**{var_name: value})
                            if text.lower() not in existing_texts:
                                generated.append(text)
                        except (KeyError, ValueError):
                            continue
                            
            elif len(template_vars) == 2:
                # Template cÃ³ 2 biáº¿n
                var1, var2 = template_vars
                if var1 in variables and var2 in variables:
                    for val1 in variables[var1][:5]:
                        for val2 in variables[var2][:5]:
                            try:
                                text = template.format(**{var1: val1, var2: val2})
                                if text.lower() not in existing_texts:
                                    generated.append(text)
                            except (KeyError, ValueError):
                                continue
            
            # Limit sá»‘ lÆ°á»£ng Ä‘á»ƒ trÃ¡nh quÃ¡ nhiá»u
            if len(generated) >= count:
                break
                
        return generated[:count]
    
    def remove_duplicates_and_similar(self, data: List[Dict], similarity_threshold: float = 0.9) -> List[Dict]:
        """Loáº¡i bá» trÃ¹ng láº·p vÃ  tÆ°Æ¡ng tá»±"""
        from difflib import SequenceMatcher
        
        unique_data = []
        seen_texts = set()
        
        for item in data:
            text = item['text'].lower().strip()
            
            # Check exact duplicate
            if text in seen_texts:
                continue
                
            # Check similarity vá»›i existing texts
            is_similar = False
            for existing in seen_texts:
                similarity = SequenceMatcher(None, text, existing).ratio()
                if similarity > similarity_threshold:
                    is_similar = True
                    break
            
            if not is_similar:
                unique_data.append(item)
                seen_texts.add(text)
        
        return unique_data
    
    def save_augmented_dataset(self, data: List[Dict], output_path: str):
        """LÆ°u dataset Ä‘Ã£ augment"""
        df = pd.DataFrame(data)
        
        # Shuffle data
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # Save with proper encoding
        df.to_csv(output_path, index=False, encoding='utf-8-sig', quoting=1)
        
        print(f"ğŸ’¾ ÄÃ£ lÆ°u {len(df)} máº«u vÃ o {output_path}")
        
        # Print statistics
        print(f"\nğŸ“Š Thá»‘ng kÃª dataset má»›i:")
        intent_dist = df['intent'].value_counts()
        for intent, count in intent_dist.items():
            print(f"  {intent}: {count}")
        
        print(f"\nğŸ“ˆ Confidence distribution:")
        conf_dist = df['confidence'].value_counts()
        for conf, count in conf_dist.items():
            print(f"  {conf}: {count}")

def main():
    print("ğŸš€ Smart Dataset Augmentation")
    print("=" * 50)
    
    # Initialize augmenter
    augmenter = SmartDatasetAugmenter()
    
    # Load existing clean data
    input_file = 'e:/MedCare/data/medical_intent_dataset_v2_clean.csv'
    df = augmenter.load_existing_data(input_file)
    print(f"ğŸ“‚ Loaded {len(df)} clean samples")
    
    # Generate smart augmentation
    target_size = 5000
    augmented_data = augmenter.generate_smart_combinations(df, target_size)
    print(f"ğŸ¯ Generated {len(augmented_data)} total samples")
    
    # Remove duplicates and very similar texts
    print("ğŸ§¹ Removing duplicates and similar texts...")
    clean_data = augmenter.remove_duplicates_and_similar(augmented_data, similarity_threshold=0.85)
    print(f"âœ… After cleaning: {len(clean_data)} unique samples")
    
    # Save augmented dataset
    output_file = 'e:/MedCare/data/medical_intent_training_dataset_5k_smart.csv'
    augmenter.save_augmented_dataset(clean_data, output_file)
    
    print(f"\nğŸ‰ HoÃ n thÃ nh! Dataset thÃ´ng minh Ä‘Ã£ Ä‘Æ°á»£c táº¡o:")
    print(f"   ğŸ“ Input: {input_file} ({len(df)} máº«u)")
    print(f"   ğŸ“ Output: {output_file} ({len(clean_data)} máº«u)")
    print(f"   ğŸ“ˆ TÄƒng trÆ°á»Ÿng: {len(clean_data) - len(df)} máº«u má»›i")

if __name__ == "__main__":
    main()