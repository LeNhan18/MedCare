"""
Simple Enhanced NER Data Generator  
Kh√¥ng c·∫ßn external dependencies
"""

import json
import os

def create_enhanced_disease_examples():
    """T·∫°o examples cho DISEASE detection"""
    diseases = [
        'vi√™m h·ªçng', 'vi√™m ph·ªïi', 'vi√™m d·∫° d√†y', 'vi√™m gan', 'vi√™m th·∫≠n',
        'ti·ªÉu ƒë∆∞·ªùng', 'cao huy·∫øt √°p', 'h·∫° huy·∫øt √°p', 'gout', 'hen suy·ªÖn',
        'tr·∫ßm c·∫£m', 'lo √¢u', 'm·∫•t ng·ªß', 'ƒëau n·ª≠a ƒë·∫ßu', 'c·∫£m l·∫°nh', 'c·∫£m c√∫m'
    ]
    
    templates = [
        "T√¥i b·ªã {disease} c√≥ nguy hi·ªÉm kh√¥ng?",
        "{disease} c√≥ th·ªÉ ƒëi·ªÅu tr·ªã ƒë∆∞·ª£c kh√¥ng?", 
        "Tri·ªáu ch·ª©ng c·ªßa {disease} l√† g√¨?",
        "Ng∆∞·ªùi b·ªánh {disease} c·∫ßn ki√™ng g√¨?",
        "Nguy√™n nh√¢n g√¢y {disease} l√† g√¨?",
    ]
    
    examples = []
    for disease in diseases:
        for template in templates:
            text = template.format(disease=disease)
            tokens = text.split()
            labels = ['O'] * len(tokens)
            
            # Find and label disease
            disease_tokens = disease.split()
            for i in range(len(tokens) - len(disease_tokens) + 1):
                if tokens[i:i+len(disease_tokens)] == disease_tokens:
                    labels[i] = 'B-DISEASE'
                    for j in range(1, len(disease_tokens)):
                        labels[i+j] = 'I-DISEASE'
                    break
            
            examples.append({
                'text': text,
                'tokens': tokens,
                'labels': labels,
                'intent': 'general_health'
            })
    
    return examples

def create_enhanced_body_part_examples():
    """T·∫°o examples cho BODY_PART detection"""
    body_parts = [
        'ƒë·∫ßu', 'm·∫∑t', 'm·∫Øt', 'tai', 'm≈©i', 'mi·ªáng', 'h·ªçng', 'c·ªï',
        'vai', 'tay', 'ng·ª±c', 'l∆∞ng', 'b·ª•ng', 'ch√¢n', 'tim', 'ph·ªïi',
        'gan', 'th·∫≠n', 'd·∫° d√†y', 'da'
    ]
    
    templates = [
        "ƒêau ·ªü {body_part} c√≥ nguy hi·ªÉm kh√¥ng?",
        "{body_part} t√¥i b·ªã s∆∞ng v√† ƒë·ªè",
        "L√†m sao ƒë·ªÉ gi·∫£m ƒëau {body_part}?",
        "{body_part} b·ªã ng·ª©a",
        "ChƒÉm s√≥c {body_part} nh∆∞ th·∫ø n√†o?",
    ]
    
    examples = []
    for body_part in body_parts:
        for template in templates:
            text = template.format(body_part=body_part)
            tokens = text.split()
            labels = ['O'] * len(tokens)
            
            # Find and label body part
            body_part_tokens = body_part.split()
            for i in range(len(tokens) - len(body_part_tokens) + 1):
                if tokens[i:i+len(body_part_tokens)] == body_part_tokens:
                    labels[i] = 'B-BODY_PART'
                    for j in range(1, len(body_part_tokens)):
                        labels[i+j] = 'I-BODY_PART'
                    break
            
            examples.append({
                'text': text,
                'tokens': tokens,
                'labels': labels,
                'intent': 'symptom_inquiry'
            })
    
    return examples

def main():
    print("üöÄ Creating Enhanced NER Training Data...")
    
    # Load existing data
    original_path = 'z:/MedCare/medical-chatbot/data/processed/ner_training_data.json'
    
    try:
        with open(original_path, 'r', encoding='utf-8') as f:
            original_data = json.load(f)
        print(f"Loaded {len(original_data)} original samples")
    except Exception as e:
        print(f"Error loading original data: {e}")
        original_data = []
    
    # Generate enhanced examples
    print("Generating DISEASE examples...")
    disease_examples = create_enhanced_disease_examples()
    print(f"Created {len(disease_examples)} DISEASE examples")
    
    print("Generating BODY_PART examples...")
    body_part_examples = create_enhanced_body_part_examples()
    print(f"Created {len(body_part_examples)} BODY_PART examples")
    
    # Combine data
    enhanced_data = original_data + disease_examples + body_part_examples
    
    print(f"\nüìä ENHANCED DATASET SUMMARY:")
    print(f"  Original samples: {len(original_data)}")
    print(f"  DISEASE samples: {len(disease_examples)}")
    print(f"  BODY_PART samples: {len(body_part_examples)}")
    print(f"  Total samples: {len(enhanced_data)}")
    
    # Save enhanced data
    output_path = 'z:/MedCare/medical-chatbot/data/processed/ner_training_data_enhanced.json'
    
    # Create directory if it doesn't exist
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Enhanced data saved to: {output_path}")
    
    # Show some examples
    print(f"\nüß™ SAMPLE ENHANCED EXAMPLES:")
    
    print("\nDISEASE examples:")
    for i, example in enumerate(disease_examples[:3]):
        print(f"  {i+1}. {example['text']}")
        entity_pairs = [(token, label) for token, label in zip(example['tokens'], example['labels']) if label != 'O']
        print(f"     Entities: {entity_pairs}")
    
    print("\nBODY_PART examples:")  
    for i, example in enumerate(body_part_examples[:3]):
        print(f"  {i+1}. {example['text']}")
        entity_pairs = [(token, label) for token, label in zip(example['tokens'], example['labels']) if label != 'O']
        print(f"     Entities: {entity_pairs}")

if __name__ == "__main__":
    main()